{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbd04b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "538674b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing 10 files from ./amatol-test …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing files:  10%|█         | 1/10 [00:01<00:15,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added 1 chunks from books/iron_age/p483.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing files:  20%|██        | 2/10 [00:02<00:09,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added 4 chunks from books/amatol_book/p014-018.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing files:  30%|███       | 3/10 [00:03<00:07,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added 2 chunks from books/amatol_book/p225.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing files:  40%|████      | 4/10 [00:04<00:06,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added 3 chunks from books/amatol_book/p135-136.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing files:  50%|█████     | 5/10 [00:05<00:04,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added 3 chunks from books/amatol_book/p025-027.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing files:  60%|██████    | 6/10 [00:05<00:03,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added 3 chunks from books/amatol_book/p061-062.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing files:  70%|███████   | 7/10 [00:06<00:01,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added 3 chunks from books/amatol_book/p253-254.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing files:  80%|████████  | 8/10 [00:06<00:01,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added 2 chunks from books/amatol_book/p007.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing files:  90%|█████████ | 9/10 [00:06<00:00,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added 1 chunks from books/amatol_book/p179.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing files: 100%|██████████| 10/10 [00:07<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added 3 chunks from books/amatol_book/p181-182.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Qdrant\n",
    "from qdrant_client import QdrantClient\n",
    "from tqdm import tqdm\n",
    "from qdrant_client.models import VectorParams, Distance\n",
    "\n",
    "from text_parsers.unified_parser import parse_file\n",
    "\n",
    "\n",
    "# --- Settings ---\n",
    "COLLECTION_NAME = 'amatol_docs'\n",
    "ROOT_DIR = './amatol-test'  # Modify this as needed\n",
    "\n",
    "# --- Step 1: Recursively find all .txt files ---\n",
    "def find_txt_files(root_dir: str) -> list[Path]:\n",
    "    return [p for p in Path(root_dir).rglob('*.txt')]\n",
    "\n",
    "# --- Step 2: Load ONE file and attach metadata ---\n",
    "# from journal_parser import parse_journal_article\n",
    "\n",
    "def load_one_document(path: Path, root_dir: str):\n",
    "    parsed = parse_file(str(path))  # unified output\n",
    "    return [Document(page_content=parsed[\"page_content\"], metadata=parsed[\"metadata\"])]\n",
    "\n",
    "# --- Step 3: Chunk helper ---\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain.schema import Document\n",
    "\n",
    "def adaptive_chunk_documents(docs: list[Document], model: str = 'text-embedding-3-small') -> list[Document]:\n",
    "    \"\"\"Take a list of Documents, split adaptively, return list of Documents.\"\"\"\n",
    "    out_docs = []\n",
    "    import tiktoken\n",
    "    enc = tiktoken.encoding_for_model(model)\n",
    "\n",
    "    for doc in docs:\n",
    "        text = doc.page_content\n",
    "        token_count = len(enc.encode(text))\n",
    "\n",
    "        if token_count < 500:\n",
    "            out_docs.append(doc)  # keep whole\n",
    "        elif token_count < 1500:\n",
    "            splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "                model_name=model, chunk_size=500, chunk_overlap=80\n",
    "            )\n",
    "            out_docs.extend(splitter.split_documents([doc]))\n",
    "        else:\n",
    "            splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "                model_name=model, chunk_size=800, chunk_overlap=100\n",
    "            )\n",
    "            out_docs.extend(splitter.split_documents([doc]))\n",
    "\n",
    "    return out_docs\n",
    "\n",
    "\n",
    "def _embedding_dim(embeddings) -> int:\n",
    "    return len(embeddings.embed_query('dim?'))\n",
    "\n",
    "def _ensure_collection(client: QdrantClient, name: str, embeddings) -> None:\n",
    "    if not client.collection_exists(name):\n",
    "        dim = _embedding_dim(embeddings)\n",
    "        client.create_collection(\n",
    "            collection_name=name,\n",
    "            vectors_config=VectorParams(size=dim, distance=Distance.COSINE),\n",
    "        )\n",
    "\n",
    "# --- Step 4: Process files ONE AT A TIME ---\n",
    "def embed_directory_one_file_at_a_time(root_dir: str, collection_name: str) -> None:\n",
    "    txt_paths = find_txt_files(root_dir)\n",
    "    if not txt_paths:\n",
    "        print(f'No .txt files found under {root_dir}')\n",
    "        return\n",
    "\n",
    "    embeddings = OpenAIEmbeddings(model='text-embedding-3-small')\n",
    "    client = QdrantClient(host='localhost', port=6333)\n",
    "    _ensure_collection(client, collection_name, embeddings)\n",
    "    vs = Qdrant(client=client, collection_name=collection_name, embeddings=embeddings)\n",
    "\n",
    "    print(f'Indexing {len(txt_paths)} files from {root_dir} …')\n",
    "    for path in tqdm(txt_paths, desc='Indexing files'):\n",
    "        docs = load_one_document(path, root_dir)\n",
    "        chunks = adaptive_chunk_documents(docs)\n",
    "        vs.add_documents(chunks)\n",
    "        print(f'  Added {len(chunks)} chunks from {path.relative_to(root_dir)}')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    embed_directory_one_file_at_a_time(ROOT_DIR, COLLECTION_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0890222",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
